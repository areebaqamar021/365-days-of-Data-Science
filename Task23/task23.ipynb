{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bd9e9d-a4bf-4fe0-98a4-29fb171bf7e5",
   "metadata": {},
   "source": [
    "# Regression Models using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cad725-f732-4ddc-bd8b-92d79a6024da",
   "metadata": {},
   "source": [
    "## 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a83394-17de-4fc5-839c-3b2825c9708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.00\n",
      "Random Forest Classifier Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Logistic Regression\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Example 2: Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Random Forest Classifier Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb3ed6-01fe-4939-9c46-f5da5c4512a8",
   "metadata": {},
   "source": [
    "## 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5780e55-04ee-4763-8d1f-4f7846d3e9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.56, R-squared: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Linear Regression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Linear Regression MSE: {mse:.2f}, R-squared: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4097fe-f9d2-4f7d-a0a2-cd9e10738ad3",
   "metadata": {},
   "source": [
    "## 3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf24005-15aa-413e-8336-bd04e91963f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\areeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Silhouette Score: 0.55\n",
      "GMM Silhouette Score: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example 1: K-Means Clustering\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load dataset\n",
    "X, _ = load_iris(return_X_y=True)\n",
    "\n",
    "# Train the model\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "labels = model.fit_predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "score = silhouette_score(X, labels)\n",
    "print(f'K-Means Silhouette Score: {score:.2f}')\n",
    "\n",
    "#Example 2: Gaussian Mixture Model (GMM)\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Train the model\n",
    "model = GaussianMixture(n_components=3, random_state=42)\n",
    "labels = model.fit_predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "score = silhouette_score(X, labels)\n",
    "print(f'GMM Silhouette Score: {score:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e624e7-05d3-4336-8d68-b9ac1d1130ea",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca57ed6-8d0a-4244-a287-1fe890b06757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.92461872 0.05306648]\n",
      "t-SNE completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load dataset\n",
    "X, _ = load_iris(return_X_y=True)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "print(f'Explained variance ratio: {pca.explained_variance_ratio_}')\n",
    "\n",
    "#Example 2: t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced = tsne.fit_transform(X)\n",
    "\n",
    "print('t-SNE completed successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
